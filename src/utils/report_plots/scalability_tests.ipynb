{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Packages\n",
    "import os\n",
    "import sys\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from wandb.sdk import wandb_run\n",
    "\n",
    "import time\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "sys.path.append('/home/augustsemrau/drive/bachelor/TGML/src')\n",
    "\n",
    "\n",
    "\n",
    "### Code imports\n",
    "## Data\n",
    "from data.synthetic.datasets.init_params import get_initial_parameters\n",
    "from data.synthetic.builder import DatasetBuilder\n",
    "from data.synthetic.stepwisebuilder import StepwiseDatasetBuilder\n",
    "from data.synthetic.sampling.constantvelocity import ConstantVelocitySimulator\n",
    "from data.synthetic.sampling.tensor_stepwiseconstantvelocity import StepwiseConstantVelocitySimulator\n",
    "\n",
    "## Models\n",
    "from models.nodynamics import NoDynamicsModel\n",
    "from models.constantvelocity.standard import ConstantVelocityModel\n",
    "from models.constantvelocity.vectorized import VectorizedConstantVelocityModel\n",
    "from models.constantvelocity.stepwise import StepwiseVectorizedConstantVelocityModel\n",
    "from models.constantvelocity.stepwise_stepbeta import StepwiseVectorizedConstantVelocityModel as MultiBetaStepwise\n",
    "from models.constantvelocity.standard_gt import GTConstantVelocityModel  \n",
    "from models.constantvelocity.stepwise_gt import GTStepwiseConstantVelocityModel\n",
    "from models.constantvelocity.stepwise_gt_stepbeta import GTStepwiseConstantVelocityModel as GTMultiBetaStepwise\n",
    "\n",
    "## Training Gym's\n",
    "from traintestgyms.ignitegym import TrainTestGym\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parse Arguments for running in terminal\n",
    "    arg_parser = ArgumentParser()\n",
    "    arg_parser.add_argument('--seed', '-seed', default=1, type=int)\n",
    "    arg_parser.add_argument('--device', '-device', default='cpu', type=str)\n",
    "    arg_parser.add_argument('--learning_rate', '-LR', default=0.025, type=float)\n",
    "    arg_parser.add_argument('--num_epochs', '-NE', default=10, type=int)\n",
    "    arg_parser.add_argument('--train_batch_size', '-TBS', default=-1, type=int)\n",
    "    arg_parser.add_argument('--real_data', '-RD', default=0, type=int)\n",
    "    arg_parser.add_argument('--dataset_number', '-DS', default=3, type=int)\n",
    "    arg_parser.add_argument('--training_type', '-TT', default=0, type=int)\n",
    "    arg_parser.add_argument('--vectorized', '-VEC', default=2, type=int)\n",
    "    arg_parser.add_argument('--remove_node_pairs_b', '-T1', default=0, type=int)\n",
    "    arg_parser.add_argument('--remove_interactions_b', '-T2', default=0, type=int)\n",
    "    arg_parser.add_argument('--steps', '-steps', default=0, type=int)\n",
    "    arg_parser.add_argument('--step_beta', '-SB', action='store_true')\n",
    "    arg_parser.add_argument('--keep_rotation', '-KR', action='store_true')\n",
    "    arg_parser.add_argument('--animation', '-ani', action='store_true')\n",
    "    arg_parser.add_argument('--animation_time_points', '-ATP', default=500, type=int)\n",
    "    arg_parser.add_argument('--velocity_gamma_regularization', '-VGR', default=None, type=float)\n",
    "    arg_parser.add_argument('--wandb_entity', '-WE', default='augustsemrau', type=str)\n",
    "    arg_parser.add_argument('--wandb_project', '-WP', default='TGMLRQ2_1', type=str)\n",
    "    arg_parser.add_argument('--wandb_run_name', '-WRN', default=None, type=str)\n",
    "    arg_parser.add_argument('--wandb_group', '-WG', default=None, type=str)\n",
    "    args = arg_parser.parse_args()\n",
    "\n",
    "    ## Set all input arguments\n",
    "    seed = args.seed\n",
    "    learning_rate = args.learning_rate\n",
    "    num_epochs = args.num_epochs\n",
    "    train_batch_size = args.train_batch_size\n",
    "    dataset_number = args.dataset_number\n",
    "    training_type = args.training_type\n",
    "    vectorized = args.vectorized\n",
    "    remove_node_pairs_b = args.remove_node_pairs_b\n",
    "    remove_interactions_b = args.remove_interactions_b\n",
    "    device = args.device\n",
    "    real_data = args.real_data\n",
    "    num_steps = args.steps\n",
    "    step_beta = args.step_beta\n",
    "    keep_rotation = args.keep_rotation\n",
    "    animation = args.animation\n",
    "    animation_time_points = args.animation_time_points\n",
    "    velocity_gamma_regularization = args.velocity_gamma_regularization\n",
    "    wandb_entity= args.wandb_entity\n",
    "    wandb_project = args.wandb_project\n",
    "    wandb_run_name = args.wandb_run_name\n",
    "    wandb_group = args.wandb_group\n",
    "\n",
    "    ## Seeding of model run\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.seterr(all='raise')\n",
    "\n",
    " \n",
    "    ### WandB initialization\n",
    "    ## Set input parameters as config for Weights and Biases\n",
    "    wandb_config = {'seed': seed,\n",
    "                    'device': device,\n",
    "                    'learning_rate': learning_rate,\n",
    "                    'vectorized': vectorized,  # 0 = non-vectorized, 1 = vectorized, 2 = stepwise\n",
    "                    'training_type': training_type,  # 0 = non-sequential training, 1 = sequential training\n",
    "                    'num_epochs': num_epochs,\n",
    "                    'remove_nodepairs': remove_node_pairs_b,\n",
    "                    'remove_interactions': remove_interactions_b,\n",
    "                    'num_steps': num_steps,\n",
    "                    'train_batch_size': train_batch_size,\n",
    "                    'velocity_gamma_regularization': velocity_gamma_regularization\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing node count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize WandB for logging config and metrics\n",
    "wandb.init(project=wandb_project, name=wandb_run_name, \n",
    "            entity=wandb_entity, group=wandb_group, config=wandb_config)\n",
    "\n",
    "\n",
    "## Device\n",
    "for dev in ['cpu','cuda']:\n",
    "    device = dev\n",
    "    print(f'Running with pytorch device: {device}')\n",
    "    torch.pi = torch.tensor(torch.acos(torch.zeros(1)).item()*2).to(device)\n",
    "    torch.eps = torch.tensor(np.finfo(float).eps).to(device) \n",
    "    \n",
    "    mean_runtimes = []\n",
    "\n",
    "    interaction_count = []\n",
    "    num_nodes_list = [2, 4 ,6 ,8 ,10,12,14,16,18,20,22 ,24 ,26 ,28, 30 ,34 ,38, 42, 46, 50, 60]\n",
    "\n",
    "    for i in num_nodes_list:\n",
    "        num_nodes = i\n",
    "        num_steps = 4\n",
    "        beta = 5.\n",
    "        runtimes = []\n",
    "        for i in range(1):\n",
    "\n",
    "            z0, v0, true_beta, model_beta, max_time = get_initial_parameters(dataset_number=dataset_number, vectorized=vectorized, num_nodes=num_nodes, beta=beta)\n",
    "            if num_steps == 0:\n",
    "                num_steps = v0.shape[2]\n",
    "            num_nodes = z0.shape[0]\n",
    "\n",
    "            simulator = StepwiseConstantVelocitySimulator(starting_positions=z0, velocities=v0, max_time=max_time, beta=true_beta, seed=seed)\n",
    "            data_builder = StepwiseDatasetBuilder(simulator=simulator, device=device, normalization_max_time=None)\n",
    "            dataset_full = data_builder.build_dataset(num_nodes, time_column_idx=2)\n",
    "            dataset = dataset_full[:10000]\n",
    "            dataset = dataset_full\n",
    "            max_time = max(dataset[:,2])\n",
    "\n",
    "            dataset_size = len(dataset)\n",
    "            print(dataset_size)\n",
    "            if i == 0 and dev == 'cuda':\n",
    "                interaction_count.append(dataset_size)\n",
    "\n",
    "            num_dyads = (num_nodes * (num_nodes - 1)) / 2\n",
    "            train_batch_size = train_batch_size if train_batch_size > 0 else dataset_size\n",
    "\n",
    "            \n",
    "            ### Setup Model: Either non-vectorized, vectorized or stepwise\n",
    "            if vectorized == -1:\n",
    "                model = NoDynamicsModel(n_points=num_nodes, beta=model_beta).to(device, dtype=torch.float32)\n",
    "            if vectorized == 0:\n",
    "                model = ConstantVelocityModel(n_points=num_nodes, beta=model_beta).to(device, dtype=torch.float32)\n",
    "            elif vectorized == 1:\n",
    "                model = VectorizedConstantVelocityModel(n_points=num_nodes, beta=model_beta, device=device, z0=z0, v0=v0, true_init=True).to(device, dtype=torch.float32)\n",
    "            elif vectorized == 2:\n",
    "                last_time_point = dataset[:,2][-1].item()\n",
    "                if isinstance(model_beta, np.ndarray):\n",
    "                    model = MultiBetaStepwise(n_points=num_nodes, beta=model_beta, steps=num_steps, max_time=last_time_point, \n",
    "                                                device=device, z0=z0, v0=v0, true_init=False).to(device, dtype=torch.float32)\n",
    "                else:\n",
    "                    model = StepwiseVectorizedConstantVelocityModel(n_points=num_nodes, beta=model_beta, steps=num_steps, \n",
    "                                    max_time=last_time_point, device=device, z0=z0, v0=v0, v0_init=training_type, \n",
    "                                    gamma=velocity_gamma_regularization).to(device, dtype=torch.float32)\n",
    "                    \n",
    "            ## Optimizer is initialized here, Adam is used\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "            ### Model training: Either non-sequential or sequential\n",
    "            metrics = {'avg_train_loss': [], 'beta_est': []}\n",
    "            \n",
    "            ## Non-sequential model training\n",
    "            if training_type == 0:\n",
    "                model.z0.requires_grad, model.v0.requires_grad, model.beta.requires_grad = True, True, True\n",
    "                gym = TrainTestGym(dataset=dataset, \n",
    "                                    model=model, \n",
    "                                    device=device, \n",
    "                                    batch_size=train_batch_size, \n",
    "                                    optimizer=optimizer, \n",
    "                                    metrics=metrics, \n",
    "                                    time_column_idx=2,\n",
    "                                    wandb_handler = wandb,\n",
    "                                    num_dyads=num_dyads,\n",
    "                                    keep_rotation=keep_rotation)\n",
    "                start_time = time.time()\n",
    "                gym.train_test_model(epochs=num_epochs)\n",
    "                end_time = time.time()\n",
    "            \n",
    "            runtime = (end_time - start_time)\n",
    "            runtimes.append(runtime)\n",
    "            print('')\n",
    "            print(runtime)\n",
    "            print(num_nodes)\n",
    "            print(num_steps)\n",
    "            print(beta)\n",
    "        mean_runtimes.append(sum(runtimes) / 5)\n",
    "        # print(mean_runtimes)\n",
    "    if dev == 'cpu':\n",
    "        cpu_times = mean_runtimes\n",
    "        wandb.log({'cpu_times': cpu_times})\n",
    "    else:\n",
    "        cuda_times = mean_runtimes\n",
    "        wandb.log({'cuda_times': cuda_times})\n",
    "        \n",
    "print(interaction_count)\n",
    "print(cpu_times)\n",
    "print(cuda_times)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10, 6), facecolor='w', edgecolor='k')\n",
    "ax.plot(num_nodes_list, np.asarray(cpu_times)/num_epochs, linestyle='-', label='CPU')\n",
    "ax.plot(num_nodes_list, np.asarray(cuda_times)/num_epochs, linestyle='-', label='CUDA')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Number of Nodes')\n",
    "ax.set_ylabel('Runtime per Epoch in Seconds')\n",
    "ax.set_title('Runtime per Epoch given number of Nodes for SCVM on CPU and CUDA')\n",
    "\n",
    "wandb.log({'Interactions_runtime_Plot': wandb.Image(fig)})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing step count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Device\n",
    "for dev in ['cpu','cuda']:\n",
    "    device = dev\n",
    "    print(f'Running with pytorch device: {device}')\n",
    "    torch.pi = torch.tensor(torch.acos(torch.zeros(1)).item()*2).to(device)\n",
    "    torch.eps = torch.tensor(np.finfo(float).eps).to(device) \n",
    "    mean_runtimes = []\n",
    "    interaction_count = []\n",
    "\n",
    "    num_steps_list = [4,8,12,16,20,30,40,50,75,100,150,200,250,300,350,400,450,500,750,1000]\n",
    "    for i in num_steps_list:\n",
    "        num_nodes = 4\n",
    "        num_steps = i\n",
    "        beta = 5.\n",
    "        runtimes = []\n",
    "        for i in range(1):\n",
    "\n",
    "            z0, v0, true_beta, model_beta, max_time = get_initial_parameters(dataset_number=dataset_number, vectorized=vectorized, num_nodes=num_nodes, beta=beta)\n",
    "            if num_steps == 0:\n",
    "                num_steps = v0.shape[2]\n",
    "            num_nodes = z0.shape[0]\n",
    "\n",
    "            simulator = StepwiseConstantVelocitySimulator(starting_positions=z0, velocities=v0, max_time=max_time, beta=true_beta, seed=seed)\n",
    "            data_builder = StepwiseDatasetBuilder(simulator=simulator, device=device, normalization_max_time=None)\n",
    "            dataset_full = data_builder.build_dataset(num_nodes, time_column_idx=2)\n",
    "            # dataset = dataset_full[:10000]\n",
    "            dataset = dataset_full\n",
    "            max_time = max(dataset[:,2])\n",
    "\n",
    "            dataset_size = len(dataset)\n",
    "            print(dataset_size)\n",
    "            if i == 0 and dev == 'cuda':\n",
    "                interaction_count.append(dataset_size)\n",
    "\n",
    "            num_dyads = (num_nodes * (num_nodes - 1)) / 2\n",
    "            train_batch_size = train_batch_size if train_batch_size > 0 else dataset_size\n",
    "\n",
    "            \n",
    "            ### Setup Model: Either non-vectorized, vectorized or stepwise\n",
    "            if vectorized == -1:\n",
    "                model = NoDynamicsModel(n_points=num_nodes, beta=model_beta).to(device, dtype=torch.float32)\n",
    "            if vectorized == 0:\n",
    "                model = ConstantVelocityModel(n_points=num_nodes, beta=model_beta).to(device, dtype=torch.float32)\n",
    "            elif vectorized == 1:\n",
    "                model = VectorizedConstantVelocityModel(n_points=num_nodes, beta=model_beta, device=device, z0=z0, v0=v0, true_init=True).to(device, dtype=torch.float32)\n",
    "            elif vectorized == 2:\n",
    "                last_time_point = dataset[:,2][-1].item()\n",
    "                if isinstance(model_beta, np.ndarray):\n",
    "                    model = MultiBetaStepwise(n_points=num_nodes, beta=model_beta, steps=num_steps, max_time=last_time_point, \n",
    "                                                device=device, z0=z0, v0=v0, true_init=False).to(device, dtype=torch.float32)\n",
    "                else:\n",
    "                    model = StepwiseVectorizedConstantVelocityModel(n_points=num_nodes, beta=model_beta, steps=num_steps, \n",
    "                                    max_time=last_time_point, device=device, z0=z0, v0=v0, v0_init=training_type, \n",
    "                                    gamma=velocity_gamma_regularization).to(device, dtype=torch.float32)\n",
    "                    \n",
    "            ## Optimizer is initialized here, Adam is used\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "            ### Model training: Either non-sequential or sequential\n",
    "            metrics = {'avg_train_loss': [], 'beta_est': []}\n",
    "            \n",
    "            ## Non-sequential model training\n",
    "            if training_type == 0:\n",
    "                model.z0.requires_grad, model.v0.requires_grad, model.beta.requires_grad = True, True, True\n",
    "                gym = TrainTestGym(dataset=dataset, \n",
    "                                    model=model, \n",
    "                                    device=device, \n",
    "                                    batch_size=train_batch_size, \n",
    "                                    optimizer=optimizer, \n",
    "                                    metrics=metrics, \n",
    "                                    time_column_idx=2,\n",
    "                                    wandb_handler = wandb,\n",
    "                                    num_dyads=num_dyads,\n",
    "                                    keep_rotation=keep_rotation)\n",
    "                start_time = time.time()\n",
    "                gym.train_test_model(epochs=num_epochs)\n",
    "                end_time = time.time()\n",
    "            \n",
    "            runtime = (end_time - start_time)\n",
    "            runtimes.append(runtime)\n",
    "            print('')\n",
    "            print(runtime)\n",
    "            print(num_nodes)\n",
    "            print(num_steps)\n",
    "            print(beta)\n",
    "        mean_runtimes.append(sum(runtimes) / 5)\n",
    "        # print(mean_runtimes)\n",
    "    if dev == 'cpu':\n",
    "        cpu_times = mean_runtimes\n",
    "        wandb.log({'cpu_times': cpu_times})\n",
    "\n",
    "    else:\n",
    "        cuda_times = mean_runtimes\n",
    "        wandb.log({'cuda_times': cuda_times})\n",
    "        \n",
    "print(interaction_count)\n",
    "print(cpu_times)\n",
    "print(cuda_times)\n",
    "fig, ax = plt.subplots(1,1, figsize=(10, 6), facecolor='w', edgecolor='k')\n",
    "ax.plot(num_steps_list, np.asarray(cpu_times)/num_epochs, linestyle='-', label='CPU')\n",
    "ax.plot(num_steps_list, np.asarray(cuda_times)/num_epochs, linestyle='-', label='CUDA')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Number of Steps')\n",
    "ax.set_ylabel('Runtime per Epoch in Seconds')\n",
    "ax.set_title('Runtime per Epoch given number of Steps for SCVM on CPU and CUDA')\n",
    "\n",
    "wandb.log({'Steps_runtime_Plot': wandb.Image(fig)})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Device\n",
    "for dev in ['cpu','cuda']:\n",
    "    device = dev\n",
    "    print(f'Running with pytorch device: {device}')\n",
    "    torch.pi = torch.tensor(torch.acos(torch.zeros(1)).item()*2).to(device)\n",
    "    torch.eps = torch.tensor(np.finfo(float).eps).to(device) \n",
    "    mean_runtimes = []\n",
    "\n",
    "    interaction_count = []\n",
    "    beta_list = [5.0, 5.25, 5.5, 5.75, 6.0, 6.25, 6.5, 6.75, 7.0, 7.25, 7.5, 7.75, 8.0, 8.25, 8.5, 8.75, 9.0]\n",
    "    for i in beta_list:\n",
    "        num_nodes = 4\n",
    "        num_steps = 4\n",
    "        beta = i\n",
    "        runtimes = []\n",
    "        for i in range(1):\n",
    "\n",
    "            z0, v0, true_beta, model_beta, max_time = get_initial_parameters(dataset_number=dataset_number, vectorized=vectorized, num_nodes=num_nodes, beta=beta)\n",
    "            if num_steps == 0:\n",
    "                num_steps = v0.shape[2]\n",
    "            num_nodes = z0.shape[0]\n",
    "\n",
    "            simulator = StepwiseConstantVelocitySimulator(starting_positions=z0, velocities=v0, max_time=max_time, beta=true_beta, seed=seed)\n",
    "            data_builder = StepwiseDatasetBuilder(simulator=simulator, device=device, normalization_max_time=None)\n",
    "            dataset_full = data_builder.build_dataset(num_nodes, time_column_idx=2)\n",
    "            # dataset = dataset_full[:10000]\n",
    "            dataset = dataset_full\n",
    "            max_time = max(dataset[:,2])\n",
    "\n",
    "            dataset_size = len(dataset)\n",
    "            print(dataset_size)\n",
    "            if i == 0 and dev == 'cuda':\n",
    "                interaction_count.append(dataset_size)\n",
    "\n",
    "            num_dyads = (num_nodes * (num_nodes - 1)) / 2\n",
    "            train_batch_size = train_batch_size if train_batch_size > 0 else dataset_size\n",
    "\n",
    "            \n",
    "            ### Setup Model: Either non-vectorized, vectorized or stepwise\n",
    "            if vectorized == -1:\n",
    "                model = NoDynamicsModel(n_points=num_nodes, beta=model_beta).to(device, dtype=torch.float32)\n",
    "            if vectorized == 0:\n",
    "                model = ConstantVelocityModel(n_points=num_nodes, beta=model_beta).to(device, dtype=torch.float32)\n",
    "            elif vectorized == 1:\n",
    "                model = VectorizedConstantVelocityModel(n_points=num_nodes, beta=model_beta, device=device, z0=z0, v0=v0, true_init=True).to(device, dtype=torch.float32)\n",
    "            elif vectorized == 2:\n",
    "                last_time_point = dataset[:,2][-1].item()\n",
    "                if isinstance(model_beta, np.ndarray):\n",
    "                    model = MultiBetaStepwise(n_points=num_nodes, beta=model_beta, steps=num_steps, max_time=last_time_point, \n",
    "                                                device=device, z0=z0, v0=v0, true_init=False).to(device, dtype=torch.float32)\n",
    "                else:\n",
    "                    model = StepwiseVectorizedConstantVelocityModel(n_points=num_nodes, beta=model_beta, steps=num_steps, \n",
    "                                    max_time=last_time_point, device=device, z0=z0, v0=v0, v0_init=training_type, \n",
    "                                    gamma=velocity_gamma_regularization).to(device, dtype=torch.float32)\n",
    "                    \n",
    "            ## Optimizer is initialized here, Adam is used\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "            ### Model training: Either non-sequential or sequential\n",
    "            metrics = {'avg_train_loss': [], 'beta_est': []}\n",
    "            \n",
    "            ## Non-sequential model training\n",
    "            if training_type == 0:\n",
    "                model.z0.requires_grad, model.v0.requires_grad, model.beta.requires_grad = True, True, True\n",
    "                gym = TrainTestGym(dataset=dataset, \n",
    "                                    model=model, \n",
    "                                    device=device, \n",
    "                                    batch_size=train_batch_size, \n",
    "                                    optimizer=optimizer, \n",
    "                                    metrics=metrics, \n",
    "                                    time_column_idx=2,\n",
    "                                    wandb_handler = wandb,\n",
    "                                    num_dyads=num_dyads,\n",
    "                                    keep_rotation=keep_rotation)\n",
    "                start_time = time.time()\n",
    "                gym.train_test_model(epochs=num_epochs)\n",
    "                end_time = time.time()\n",
    "            \n",
    "            runtime = (end_time - start_time)\n",
    "            runtimes.append(runtime)\n",
    "            print('')\n",
    "            print(runtime)\n",
    "            print(num_nodes)\n",
    "            print(num_steps)\n",
    "            print(beta)\n",
    "        mean_runtimes.append(sum(runtimes) / 5)\n",
    "        # print(mean_runtimes)\n",
    "    if dev == 'cpu':\n",
    "        cpu_times = mean_runtimes\n",
    "        wandb.log({'cpu_times': cpu_times})\n",
    "\n",
    "    else:\n",
    "        cuda_times = mean_runtimes\n",
    "        wandb.log({'cuda_times': cuda_times})\n",
    "        \n",
    "print(interaction_count)\n",
    "print(cpu_times)\n",
    "print(cuda_times)\n",
    "fig, ax = plt.subplots(1,1, figsize=(10, 6), facecolor='w', edgecolor='k')\n",
    "ax.plot(interaction_count, np.asarray(cpu_times)/num_epochs, linestyle='-', label='CPU')\n",
    "ax.plot(interaction_count, np.asarray(cuda_times)/num_epochs, linestyle='-', label='CUDA')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Number of Interactions')\n",
    "ax.set_ylabel('Runtime per Epoch in Seconds')\n",
    "ax.set_title('Runtime per Epoch given number of Interactions for SCVM on CPU and CUDA')\n",
    "\n",
    "wandb.log({'Interactions_runtime_Plot': wandb.Image(fig)})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
